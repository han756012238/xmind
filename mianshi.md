core java------------------------------------------------------------------------------------------
101.hashCode相等的两个对象一定相等吗？equals呢？反过来相等吗？
都不一定，hashCode()和equals()都是可以随便重写的。
但JDK规定，equals相等hashCode必须相等，反之就不一定。为了hash结构集合存储。
hashCode默认实现是对象在内存中的内存地址。equals默认实现是用==比较。

102.Hashtable、HashMap底层实现是什么？Hashtable和ConcurrentHashMap底层实现的区别？
Hashtable每个方法都加了sychronized，访问Hashtable的线程都必须竞争同一把锁。不接受null的key，非failFast。
ConcurrentHashMap是在一个总的哈希表下面有若干个子哈希表的一个二级哈希表。Segment锁分段技术。写线程才需要锁定而读线程不需要。put方法两次hash之间获得重入锁。求size先乐观再悲观，比较修改次数，size值不准确。
ConcurrentSkipListMap替代TreeMap。跳跃表：每一个结点不单单只包含指向下一个结点的指针，可能包含很多个指向后续结点的指针，这样就可以跳过一些不必要的结点，从而加快查找、删除等操作。对于一个链表内每一个结点包含多少个指向后续元素的指针，后续节点个数是通过一个随机函数生成器得到。线性结构中，向有序的链表中插入一个节点需要O(n)的时间，查找操作需要O(n)的时间。而跳跃表就可以减少查找所需时间为O(n/2)，先大步查找确定范围，再逐渐缩小迫近。ConcurrentSkipListMap线程安全的原理是利用底层的插入、删除的CAS原子性操作，通过死循环不断获取最新的结点指针来保证不会出现竞态条件。
同步类容器：Vector、HashTable、Collections.synchronizedXXX；并发类容器：ConcurrentHashMap、ConcurrentSkipListHashMap、CopyOnWriteArrayList、

103.HashMap和TreeMap的区别？底层数据结构都是什么？
HashMap每次扩容重新hash，保证了一定在16以内的数字：HashCode(Key)&(length-1)。两个线程同时rehash时容易造成循环链表，get时死循环。jdk8链表上结点数量>8转为红黑树。
TreeMap：基于红黑二叉树实现，不允许null。元素需实现Comparable(内比较器)接口或Comparator接口。
红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的

104.线程池都有什么参数？底层是如何实现的？
SingleThreadExecutor：单线程（thread异常结束时，会new一个thread补充）；FixedThreadPool：固定大小的线程池；CachedThreadPool：大小可伸缩线程池，执行结束后缓存60s，若不被调则移除线程。ScheduledThreadPool:具有时间调度特性的线程池，用DeplayedWorkQueue实现的。

参数：ThreadPoolExecutor(核心池数量,最大线程数,缓存时间,时间单位,阻塞队列,队列满时处理策略)
SynchronousQueue：直接提交策略；LinkedBlockingQueue：无界队列；ArrayListBlockingQueue：有界队列。
拒绝策略：阻塞、直接抛弃、从队列里面抛弃head、自定义

原理：假设初始化一个线程池，核心线程数是5，最大线程数是10。初始化的时候里面没有线程，当来了一个任务时，在线程池中初始化一个线程，直接到第6个任务来，这时把第6个任务放到阻塞队列中，如果5个线程中有空闲了，就会从阻塞队列中获取第6个任务。若5个线程都在running，那任务就先保存在阻塞队列中。如果队列满了，这个时候会新建一个线程执行不能保存到阻塞队列的任务，直到线程数达到10个。如果线程数也到达10个，阻塞队列也满了，则通过reject函数处理这里的任务了。若运行一段时间阻塞队列中的任务执行完了，超过核心线程数的线程会在空闲一段时间内自动回收。适用场景：秒杀。
线程数究竟设多少合理：https://mp.weixin.qq.com/s/CBGMRsk6aFYAGiYQucqF_w

105.synchronize和Lock接口的区别是什么？synchronize什么情况下是对象锁？什么情况下是全局锁？为什么？
synchronized：JVM执行的，悲观锁，抛异常，会自动释放锁。synchronized从主内存里读，结束后回写到主内存，不管是否为volatile。其中锁的获取和释放分别是monitorenter和monitorexit指令，该锁在实现上分为了偏向锁、轻量级锁和重量级锁，其中偏向锁在1.6是默认开启的，轻量级锁在多线程竞争的情况下会膨胀成重量级锁，有关锁的数据都保存在对象头中。
lock：java写的，CAS实现。condition.await()和condition.signal()线程间通信。
synchronized在非静态方法上代表对象锁，静态方法为类锁，因为调用静态方法是对象不一定创建。
悲观锁:适用于频繁更新数据情况
乐观锁:适用于读多写少

内部类无法访问非final对象：内部类对象生命周期会超过局部变量，匿名内部类对象访问的Final的局部变量都会拷贝为该对象的成员。

106.ThreadLocal如何使用的？说出你在项目中使用的例子？底层实现是什么？
通过ThreadLocal保存的数据最终是保存在Thread类的ThreadLocalMap threadLocals变量中。该Map的key为我们声明的ThreadLocal对象，value即为我们使用ThreadLocal保存的线程本地变量。
当我们调用ThreadLocal变量set方法时，那么会将TheadLocal作为key，set方法的参数做为value保存在当前线程的threadLocals中，调用get方法时类似。
存储结构的好处：线程死去的时候，线程共享变量ThreadLocalMap则销毁。
内存泄露：这个Map的确使用了弱引用，不过弱引用只是针对key。每个key都弱引用指向threadlocal，当把threadlocal实例置为null以后，没有任何强引用指向threadlocal实例，所以threadlocal将会被gc回收。弱引用保障了ThreadLocal会被回收。但我们的value却不能回收，因存在一条从current thread连接过来的强引用。只有当前thread结束以后, current thread就不会存在栈中，强引用断开。

107.volatile的工作原理是什么？
通过加入内存屏障和禁止重排序优化来实现。
代码层面实现：
对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量刷新到主内存。对于volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量。
volatile写指令顺序：普通写→StoreStore屏障→volatile写→StoreLoad屏障→普通读/写。StoreStore禁止了上面的普通写和下面的volatile写重排序，StoreLoad禁止了volatile写与下面普通读/写重排序。
volatile读指令顺序：volatile读→LoadLoad屏障→LoadStore屏障→普通读/写。LoadLoad禁止了下面所有普通读操作和上面volatile读重排序，LoadStore禁止了下面所有的写操作和上面的volatile读重排序。
系统层面实现：在多处理器下，保证各个处理器的缓存是一致的，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态。

应用场景（常用于做状态标记量）：1:多线程间状态标识；2:单例双重检查锁定；3:定期观察成员变量状态的方法。

伪共享：在计算机系统中，内存是以缓存行为单位存储的，一个缓存行存储字节的数量为2的倍数，通常为64字节。伪共享指的是在多个线程同时读写同一个缓存行的不同变量的时候，尽管这些变量之间没有任何关系，但是在多个线程之间仍然需要同步，从而导致性能下降的情况。在对称多处理器结构的系统中，伪共享是影响性能的主要因素之一，由于很难通过走查代码的方式定位伪共享的问题，因此，大家把伪共享称为“性能杀手”。

108.CAS是什么？如何实现的呢？
原理：有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。
问题：ABA，循环时间长开销大，只能保证一个共享变量的原子操作。解决方法：AtomicStampedReference，通过控制变量值的版本来保证CAS的正确性。

109.请用至少四种写法？写单例模式的实现。
饿汉模式：类加载时就创建对象；懒汉模式：synchronized修饰在方法上；双重检查锁：双重判断+同步+volatile；枚举；静态内部类(类级内部类只有在第一次被使用的时候才被会装载)：
private static class InnerSingletion {
  private static Singleton4 single = new Singleton4();
}

简述不加volatile时DCL失效原因(new Instance()时下面伪代码中2、3步可能重排)：
memory = allocate(); //1：分配对象的内存空间
ctorInstance(memory); //2：初始化对象
instance = memory; //3：设置instance指向刚分配的内存地址

110.AQS(AbstractQueuedSynchronized,队列同步器)的实现原理
ReentrantLock/Semaphore/CountDownLatch都依赖于AQS,
原理：维护了volatile int state和FIFO wait queue;
AQS内部会保存一个状态变量state，通过CAS修改该变量的值，修改成功的线程表示获取到该锁，没有修改成功，或者发现状态state已经是加锁状态，则通过一个Waiter对象封装线程，添加到等待队列中，并挂起等待被唤醒。
两种资源共享方式：可以独占/共享锁
CAS来对state状态进行操作，ReentrantLock默认nonfair，也可以fair(排队获取锁)，lock不成功进入等待队列。ReadWriteLock同时多线程读，单线程写。

111.java线程状态
new---start()->runnable--分配cpu-->running-->waiting-->blocked-->dead

Thread.sleep(millis):当前线程调用此方法，当前线程进入阻塞，但不释放对象锁，时间到后自动进入可运行状态;
Thread.yield():当前线程调用此方法，当前线程放弃获取cpu时间片，由运行状态变为可运行状态;
t.join()/t.join(millis):当前线程调用其它线程t的join方法，当前线程阻塞，但不释放对象锁，直到线程t执行完毕或者millis时间到，当前线程进入可运行状态。
obj.wait()/obj.wait(millis):当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者millis时间到自动唤醒。
notify()/notifyAll()：随机唤醒一个/所有等待该对象同步锁的线程，进入就绪队列等待CPU的调度；注意唤醒的是notify之前wait的线程，对于notify之后的wait线程是没有效果的，notify不释放锁（使用CountDownLatch可以解决notify不释放锁、不实时的问题）。

yield被打断不会抛异常，sleep会
sleep不会释放monitor，yield会

112.简述synchronized Object Monitor机制
-synchronized代码块使用了monitorenter和monitorexit指令实现。
-synchronized方法中依靠方法修饰符上的ACC_SYNCHRONIZED实现。
无论哪种实现，本质上都是对指定对象相关联的monitor的获取，这个过程是互斥性的，也就是说同一时刻只有一个线程能够成功，其它失败的线程会被阻塞，并放入到同步队列中，进入BLOCKED状态。
HotSpot虚拟机中，对象在内存中存储布局分为3块区域：对象头(Mark Word+Class对象地址)、对象实例字段、对齐填充。
估算对象大小(32位HotSpot)：class A{int i;byte b;String str;}计算：对象A一共占用了4(Mark Word)+4(类型指针)+4(i)+1(b)+4(str)=17字节，按8字节对齐原则，对象大小也就是24字节。
HotSpot中对象头的Mark Word：
存储内容|标志位|状态
对象哈希码和分代年龄|01|未锁定
指向锁记录的指针|00|轻量级锁定
指向重量级锁的指针|10|重量级锁定
空，不需要记录信息|11|GC标记
偏向线程ID、时间戳和分代年龄|01|可偏向
Mark Word用2bit标志位来显示锁类型，synchronized的对象锁就是这里标志位为10时的monitor对象，这里的‘重量级锁的指针’就是这个monitor对象的地址。
当多个线程同时请求synchronized方法或块时，monitor会设置几个虚拟逻辑数据结构来管理这些多线程：新请求的线程会首先被加入到线程排队队列中，线程阻塞，当某个拥有锁的线程unlock之后，则排队队列里的线程竞争上岗（synchronized是不公平竞争锁）。如果运行的线程调用对象的wait()后就释放锁并进入wait线程集合那边，当调用对象的notify()或notifyall()后，wait线程就到排队那边。monitor相当于含有三个房间的建筑：排队大厅(线程排队队列)、工作单间(正在运行的线程)、等待房间(wait线程集合)。
自旋锁：线程挂起和恢复操作都需要cpu从用户态转为内核态，频繁的挂起和恢复对cpu来说负荷很重，统计发现很多对象锁的锁定只会持续很短的一段时间。monitor并不把未获得锁的线程放入排队队列，而是去执行一次循环，循环结束后若发现锁已释放直接进行竞争上岗，如果竞争不到继续自旋循环。
轻量锁：在当前线程的栈帧中生成一个锁记录，锁记录只是对象头的一个拷贝，并把对象头的标志位改为00。
偏向锁：当synchronized区域长期都由同一个线程加锁、解锁。

113.简述happen-before规则。
编译器或运行时为了效率可以在允许的时候对指令进行重排序，这就引起了线程间可见性问题。通过制定一些通用规则规定某些场景某个线程修改的变量何时对另一个线程可见。happen-before不是描述实际操作的先后顺序，而是用来描述可见性的一种规则。如线程1解锁了a，接着线程2锁定了a，那么线程1解锁a之前的所有写操作都对线程2可见；如线程1写入了volatile变量v，接着线程2读取了v，那么线程1写入v对线程2可见。

114.简述字节码文件组成。
魔术、版本号、常量池、类访问标志、类和超类索引、接口表、字段表、方法表、属性表。

115.说说你了解的一个线程安全队列
● 并发-无阻塞队列-ConcurrentLinkedQueue
● 并发-阻塞队列-ArrayBlockingQueue（没有采用读写分离、add和poll不能同时进行）
 *  offer 如果队列已经满了,则不阻塞，不抛出异常
 *  offer 可设置最大阻塞时间,2秒,如果队列还是满的,则不阻塞，不抛出异常
 *  add 如果队列满了，则不阻塞，直接抛出异常
 *  put 如果队列满了,则永远阻塞, 不抛出异常
 * ---------------------------------------------------
 * peek 读取头元素不移除，队列为空,返回null,不阻塞, 不抛异常
 * poll 读取头元素并移除，队列为空,返回null,不阻塞, 不抛异常
 * poll 可指定阻塞时间,2秒,如果队列依然为空,则返回null,不抛异常
 * take 读取头元素并移除,如果队列为空,则永远阻塞,不抛出异常
● 并发-阻塞队列-LinkedBlockingQueue（读写分离、支持写入和读取并发操作）
● 并发-阻塞队列-SynchronousQueue（没有任何容量）
● 并发-阻塞队列-PriorityBlockingQueue（带优先级的阻塞队列）
● 并发-阻塞队列-DelayQueue（带有延迟功能的阻塞队列）

116.Java怎么做序列化？Java序列化过程中，编码怎么设置？
序列化：把Java对象转换为字节序列的过程。
反序列化：把字节序列恢复为Java对象的过程。
对象序列化用途：1.将对象的字节永久地保存到磁盘上；2.在网络上传送对象的字节序列。
java实现序列化：将序列化的类实现Serializable接口，使用ObjectOutputStream的writeObject()进行输出。
被transient修饰的字段不会被序列化。在被反序列化后，transient变量的值被设为初始值，如int型的是0，对象型的是null。

117.Java对象的生命周期
Created、In Use、Invisible(不可见，超出了其作用域)、Unreachable、Collected、Finalized、De-allocated

118.为什么wait()一般建议要放在循环中？
如果采用if判断，当线程从wait中唤醒时，那么将直接执行处理其他业务逻辑的代码，但这时可能出现另外一种可能，条件谓词已经不满足处理业务逻辑的条件了，从而出现错误的结果，于是有必要进行再一次判断。

119.对象在内存中的初始化过程？
要初始化一个对象，首先要加载该对象所对应的class文件，该文件的数据会被加载到永久代，并创建一个底层的instanceKlass对象代表该class，再为将要初始化的对象分配内存空间，优先在线程私有内存空间中分配大小，如果空间不足，再到eden中进行内存分配。

120.Object类的finalize方法的实现原理？
新建一个对象时，在JVM中会判断该对象对应的类是否重写了finalize方法且finalize方法体不为空，则把该对象封装成Finalizer对象，并添加到Finalizer链表。Finalizer类中会初始化一个FinalizerThread类型的线程，负责从一个引用队列中获取Finalizer对象，并执行该Finalizer对象的runFinalizer方法，最终会执行原始对象的finalize方法。

121.闭锁、栅栏、信号量
● CountDownLatch（等待事件）：允许一个或多个线程等待一系列指定操作的完成。
● CyclicBarrier（等待其它线程）：允许一组线程互相等待，直到到达某个公共屏障点，可以重复使用。
● Semaphore（限制同时访问的并发量），与RateLimiter区别：RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率，Semaphore 限制了同时访问的并发量而不是访问速率。
● Exchanger（交换数据）：表示一种两个线程可以进行互相交互对象的汇合点。

122.Java中如何停止一个线程？
Java没有为停止线程提供API。JDK1.0本来有一些像stop()、suspend()和resume()的控制方法，但是由于潜在的死锁威胁。因此在后续的JDK版本中他们被弃用了，之后Java API的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当run()或者call()方法执行完的时候线程会自动结束，如果要手动结束一个线程，可以用volatile布尔变量来退出run()方法的循环或者是取消任务来中断线程。

123.为什么wait、notify和notifyAll这些方法不在thread类里面？
JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。

为什么Thread类的sleep()和yield()方法是静态的？
Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。

124.有三个线程T1，T2，T3，怎么确保它们按顺序执行？
可以用线程类的join()方法在一个线程中启动另一个线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用T2，T2调用T1)，这样T1就会先完成而T3最后完成。

125.Fork/Join框架原理
Java7提供了的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。采用“工作窃取模式”。

JVM------------------------------------------------------------------------------------------
201.Minor GC、Major GC和Full
新生代(eden+survivor)触发Minor GC,老年代、持久代和System.gc触发Major GC。

202.请介绍一下JVM内存模型？用过哪些垃圾收集器？
内存模型：
栈+本地方法栈：每个方法执行时创建一个栈帧(保存方法的私有变量、操作数和返回值等)，栈的大小决定了方法的调用的可达深度，大于则抛stackOverflowError，没有内存支持动态扩展了则抛OutofMemoryError。
堆：新生代(eden区、survivor0区、survivor1区)和老年代
方法区(永久代)：类加载的元数据信息(常量、静态变量和编译后的代码)
程序计数器：线程记录下一条要运行的指令，方便再次被cpu调度。

垃圾回收算法：
标记清除算法：将没有标记的垃圾对象进行清除，但回收后的空间不连续。
复制算法(新生代)：内存分两块，每次使用一块。
标记整理算法(老年代)：标记后不复制，而是将对象压缩到内存的一端，然后清理界外对象。

垃圾收集器：
Serial(复制)/Serial Old(标记整理)：单线程收集，需暂停所有用户线程。
ParNew(复制)：多个线程进行收集。
Parallel Scavenge(复制)/Parallel Old(标记整理)：并行收集。
CMS(标记清除)：最小回收时间停顿并发收集器。
G1：可预测停顿时间
CMS回收过程：初始标记、并发标记、重新标记、并发清除；初始标记、重新标记这两步骤仍然需要stop the world，初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长点，但远比并发标记的时间短。

红包雨项目：-Xms2048m -Xmx12G(JVM最大可用内存，占总内存的一半) -XX:PermSize=256m -XX:MaxPermSize=512m -XX:NewRatio(年轻代和年老代的比值，官网推荐新生代占整个堆的3/8)=3 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=7 -XX:GCTimeRatio(垃圾回收时间与非垃圾回收时间的比值)=19 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC

203.线上频繁发生full gc如何处理？CPU使用率过高怎么办？说出你的思路和处理方法？
频繁full gc：
通过jstat -gcutil 14063 2000 10查看使用空间占总空间的百分比，查看gc日志各代gc前后大小变化，
通过jmap -histo[:live] pid查看堆内存中对象数量和大小。
加live后比不加live少很多大对象证明是大量的请求进入分配内存而处理不过来导致频繁full gc，反之则存在不当的引用导致内存泄露。
JVM参数中加入-XX:+DisableExplicitGC来禁止System.gc()试一下。

cpu使用率过高：
通过top命令先找到占用大量cpu资源的进程的pid(shift+p)，如pid为211。
top -Hp 211找到最耗cpu的线程，如tid为1211，将tid转换为16进制如为52f1。
使用jstack pid |grep tid -A 30打印线程栈信息(可查看类的行号)，找到cpu过高的原因。
如果这些线程是gc线程，可确定内存不足或者泄露导致的。

jinfo和一些参数可以动态修改JAVA进程的虚拟机参数。
jmap -heap pid：显示当前堆内存初始化配置+各区使用情况
jmap -dump:format=b,file=heapDump pid：打印堆快照，用jhat查看
jmap -histo:live pid会触发Full GC，GC结束后就知道live data大小，用来计算old generation应该设置的大小：Old Generation==live data*1.5

204.知道字节码吗？字节码都有哪些指令？
java字节码中用一些编码来表示指令的一些特殊操作的含义。
ldc表示将int，float或是String类型的常量值从常量池中推送至栈顶。
bipush表示将单字节（-128~127）的常量值推送至栈顶
sipush表示将一个短整型常量值（-32768-32767）推送至栈顶
iconst_1表示将int类型的1推送至栈顶（iconst_m1 ~  iconst_5）

205.讲讲类加载机制？都有哪些类加载器？这些类加载器都加载哪些类文件？说说你在项目中用到类加载器的例子？
class加载各阶段过程：
1. 加载：查找并加载类的二进制数据
2. 连接：
    - 验证： 确保被加载的类的正确性
    - 准备：为类的静态变量分配内存，并将初始化默认值（类的实例变量还没有）
    - 解析：把类中的符号引用转换为直接引用
3. 初始化：为类的静态变量赋予正确的初始值

每个类或接口被Java程序“首次主动使用”时才初始化他们。主动引用：创建类的实例、访问类或接口的静态变量或方法、反射、初始化一个类的子类、标明为启动类的类、动态语言支持。被动引用：通过子类引用父类的静态字段、通过数组定义类引用类、常量在编译阶段会存入调用类的常量池中，本质上没有直接引用到定义常量的类。

根加载器：加载java核心库；拓展类加载器：加载jre\lib\ext下的类；应用加载器：加载classpath下的类；自定义加载器。
双亲委托：先将加载任务委托给父类去加载，父类无法完成加载自己才去加载。好处：安全（jvm不会加载黑客自定义的java.lang.String类）、唯一性（类加载器和类一同确立它在jvm的唯一性）。
类加载器应用：类库隔离、字节码解密和热部署。

高版本的tomcat可以同时部署多个应用的原因？
tomcat自定义了CommonClassLoader（类库被tomcat和所有web应用共同使用）、CatalinaClassLoader（被tomcat使用，web应用不可见）、SharedClassLoader（web共享，tomcat不可见）、WebappClassLoader（仅当前web应用可见（WEB-INFO））和JasperLoader类加载器。
原因：WebApp类加载器和Jsp类加载器通常会存在多个实例，每一个应用程序对应一个WebApp类加载器。
每一个JSP文件对应一个Jsp类加载器。被修改的jsp会新建一个jsp类加载器实例。

206.YGC的大概过程？
先找出根对象，如Java栈中引用的对象、静态变量引用的对象和常量池中引用的对象等，把这些对象标记成活跃对象(可达性分析)，并复制到to区，接着遍历这些活跃对象中引用的对象并标记，找出老年代对象在eden区有引用关系的对象并标记，最后把这些标记的对象复制到to，在复制过程还要判断活跃对象的gc年龄是否已经达到阈值，如果已经达到阈值，就直接晋升到老年代，YGC结束之后把from和to的引用互换。若晋升失败，在标记阶段时，会把对象和对应的对象头数据保存在两个栈中，如果晋升失败的话，就把该对象的对象头复原。

Mysql------------------------------------------------------------------------------------------
301.mysql explain执行计划
id列：编号从1开始，子查询则编号增加。
table列：表名、别名、derived(派生表名)、null(不走表)。
select_type列：simple(不含子查询)、primary(含子查询或派生查询)、subquery(非from子查询)、derived(from型子查询)、union、union result。
type列：
 ● ALL：逐行全表扫描。如缺乏索引。
 ● index：扫描所有的索引节点，能利用上索引但是全索引扫描。如索引覆盖或利用索引进行排序。
 ● range：能根据索引做范围的扫描。如使用>、<、is null、between、in或like等运算符的查询中。
 ● ref：通过索引列可以直接引用到某些数据行。
 ● eq_ref：通过索引列直接引用某1行数据，常见于连接查询中。
 ● const、system、NULL：指查询优化到常量级别，甚至不需要查找时间。
possible_keys：可能用到的索引。
key：实际用到的索引，不能为NULL(不走索引)。
key_len列：索引最大长度。
ref列：连接查询时，前表与后表的引用关系。
extra列：
 ● using index：指使用了索引覆盖，效率非常高。
 ● using where：光靠索引定位不了，还得where判断一下。
 ● using temporary：指用上了临时表，group by与order by不同列时或别的表的列。
 ● using filesort：文件排序（文件可能在磁盘，也可能在内存)。
 ● range checked for each record：没有发现好的索引。
rows列：估计扫描多少行。

302.使用mysq索引都有哪些规则？索引是什么数据结构？B+树和B树的区别是什么？
索引选择规则：
-选择维度高的列(若结果个数/总个数>20%时，全表扫描比用索引性能更优)
-选择where,on,group by,order by中出现的列，常用的列放到前面
-离散度(多样性)更高的索引放在联合索引的前面
-复合索引尽量不要有null值(若组合索引包含NULL值的列则整个组合索引无效)
-为较长的字符串使用前缀索引
-不要在索引列上进行运算,否则索引会失效(YEAR(adddate)<2007)
-最左原则:index abc(a,b,c)→abc、ab、c分别建了索引
最左原则原因：多列索引是先按照第一列进行排序，然后在第一列排好序的基础上再对第二列排序，如果没有第一列的话，直接访问第二列，那第二列肯定是无序的，直接访问后面的列就用不到索引了。

mysal索引是B+树,B+树所有元素都在子节点且linked，所以遍历所有数据很方便。
B树比二叉查找树更加‘矮胖’，减少了IO操作。
B+树比B树的优势：1.IO次数更少；2.查询性能稳定；3.范围查询方便。

303.mysql有哪些存储引擎啊？都有什么区别？
存储引擎是针对于表的而不是针对于库的（一个库中的不同表可以使用不同的存储引擎）。
MyISAM：不支持事务、也不支持外键，优势是访问速度快；适用场景：非事务型应用、只读类应用。
 ● 并发性与锁级别-使用的是表级锁而不是行级锁，读写混合操作并发性不高
 ● 表损坏修复-对任意意外关闭而损耗的表进行检查和修复操作，而事务无法恢复
 ● 支持的索引类型-支持全文索引、前缀索引
 ● 支持数据压缩
InnoDB：具有提交、回滚和崩溃恢复能力的事务安全。
 ● 通过Redo Log和Undo Log实现事务
 ● 支持行级锁
MEMORY：在内存中的内容来创建表(HASH索引)。
Merge：一组MyISAM表的组合，操作实际上是对内部的MyISAM表进行的。

本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？
数据库是由两种类型的文件组成的，分别是数据库文件和日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。
Undo Log记录某数据被修改前的值，可以用来在事务失败时进行rollback。Redo Log记录某数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据（用于数据库缓存在内存中内容的持久性）。

304.常见的索引类型
索引是存储引擎用于快速找到记录的一种数据结构。作用：1-大大减少了服务器需要扫描的数据量；2-可以帮助服务器避免排序和临时表；3-索引可以将随机I/O变成顺序I/O。
索引的类型有B-Tree索引和哈希索引。
B-Tree索引：MyISAM使用前缀压缩技术使得索引更小，但InnoDB这按照原数据格式进行存储。MyISAM索引通过数据的物理位置引用被索引的行，而InnoDB则根据主键引用被索引的行。
哈希索引：只能精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码，哈希码是一个较小的值。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针（哈希索引只包含哈希值和行指针）。

Hash索引优点：检索效率非常高，可一次定位，不像B-Tree索引需要从根节点到叶子节点，多次的IO访问。
Hash索引缺点：因hash算法是基于等值计算的，所以对于like等范围查找hash索引无效，不支持不精确查找。

305.聚簇索引与非聚簇索引？
聚簇索引是一种数据存储方式。表示数据行和相邻的键值紧凑地存储在一起的一种索引，而非聚集索引则就是普通索引了，仅仅只是对数据列创建相应的索引。

InnoDB引擎表是聚簇索引组织表，而MyISAM引擎表则是堆组织表。
MyISAM的主索引和次索引（二级索引、非聚簇索引）都指向物理行（磁盘位置），即索引树中的所有叶子节点都含有指向物理行的指针。
而InnoDB主索引树的叶子节点既存储索引值，又直接存放了该行数据，成为聚簇索引，次索引的叶子节点包含了引用行的主键列。

一个表的聚簇索引只能有唯一的一条，表对应的非聚簇索引可以有多条。聚簇索引通常默认都是主键，设置了主键，系统默认就为你加上了聚簇索引。设置其它字段作为聚簇索引：在设置主键之前手动的先添加上唯一的聚簇索引，然后再设置主键。

聚簇索引优势: 根据主键查询条目比较少时，不用回行（数据就在主键节点下）；劣势: 如果碰到不规则数据插入时，造成频繁的页分裂。次索引访问需要两次B-Tree查找。

对于索引树，新增或更新索引值时避免不了叶子节点会发生分裂（页分裂，InnoDB只聚集在同一个页面中的记录）。对于MyISAM，叶子节点只是额外存储了物理行地址，内容较小，又缓存在内存里，因此分裂速度较快。
而对于InnoDB，叶子节点存储了行数据，节点分裂的时候需要移动这些行数据，内容较大，因此分裂速度较慢（如同搬家时因家当较多，导致负载较重），一次插入最少需要修改三个页而不是一个页。

为什么InnoDB表要建议用自增列做主键？
-InnoDB的主键采用了聚簇索引，叶子节点下有行数据，因此节点的分裂将会比较慢。主键如果是无规律的，将会加速叶子节点的分裂，效率会很低。
-写入的目标页可能已从缓存中移除或没有被加载到缓存中，InnoDB不得不先找到并从磁盘读取目标页到内存中，导致了大量的随机I/O。
在InnoDB表中，尽量用与业务无关的递增的整型作为主键，这时候写入顺序是自增的，和B+数叶子节点分裂顺序一致的，存取效率是最高的。主键自增的索引树是相对平衡较好的树，查询效率是最高的。

InnoDB表自增主键可能的问题？
对于高并发工作下，InnoDB中按主键顺序插入可能会造成明显的争用。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。

覆盖索引：指如果查询的列恰好是索引的一部分，那么查询只需要在索引文件上进行，不需要回行到磁盘再找数据。这种查询速度非常快。

背景：
create table A(
  id varchar(64) primary key,
  var int,
  ...
)
在id、ver有联合索引，共1w条数据。该表有几个很长的字段varbinary(3000)。
问题：为什么select id from A order by id特别慢，而select id from A order by id,ver特别快？
原因：猜测是InnoDB引擎。因id为聚簇索引，又有多个比较长的列。导致页比较多，沿id查找时要跨好多页。而id和ver的联合索引是非聚簇索引，并没有放数据行，只含有指向主键列的指针。因此次索引体积较小，在内存中查询速度将非常快。推断1：如果是MyISAM引擎，将不存在这个问题。推断2：如果没有过长的几个插入字段，差别也不会这么大。

306.设计高并发高可用系统时数据库层面设计该怎么设计？
分表：垂直切分，将各个模块服务化。
分库：水平切分，解决单表大数据的问题，一致性hash算法。
采用内存缓存/缓存数据库+定时刷新到落地数据库来缓解数据库压力。
秒杀场景：允许请求丢失，使用队列保存较早的用户请求，再异步更新到数据库。
记流水不记账：账户表+流水表，每当有请求来就向流水表插入记录，定时对插入的记录进行统计并update账户表。

307.数据库锁都有哪些？如何实现的？
锁粒度：表级锁(不会出现死锁)、页级锁和行级锁。当一个表中的某一行被加上排它锁后，该表就不能再被加表锁。
锁级别：共享锁、排它锁。同一资源上不能同时共存共享锁和排它锁，在升级排它锁前，必须等该资源上的其它共享锁释放。
T1:update table set column1='hello' where id=10;
T2:update table set column1='world' where id=20;
若id有索引，两行各加排它锁。若id无索引，T1对整表所有行加行锁，T2等待。
next-key：包含了记录锁和间隙锁，即锁定一个范围且锁定记录本身。
共享锁：select...from lock in share mode;
排它锁：select..from for update;
使用方式：乐观锁、悲观锁。

308.mysql优化
使用慢日志查询：1.检查慢查询日志是否开启；2.记录没有使用索引的查询；3.记录查询时间超过0.5秒的sql。
分析有问题SQL：1.分析慢查询日志(查询次数多时间长sql、没有命中索引sql、io大的sql)；2.使用explain执行计划。
SQL优化：1.count(*)→count(id);2.子查询→join;3.group by→子查询;4.避免列上进行计算;5.LIKE模糊查询避免%%;6.避免使用NULL。
索引优化：1.where、group by、order by、on后出现的列;2.索引字段尽量小;3.离散度大的索引放在联合索引的前面;4.使用覆盖索引。
数据库结构优化：1.尽量使用简单的数据类型(少使用大数据类型);2.尽量使用not null;3.表的水平拆分和垂直拆分。

覆盖索引：指一个查询语句的执行只需要从辅助索引中就可以得到查询记录，而不需要回表查询。

show profile:分析性能，查询各个sql执行时间、每个sql详细时间耗费和cpu、io消耗信息。
show processlist:显示有哪些线程在运行、当前所有的连接数、通过当前的连接状态识别有问题的查询语句。

309.MySQL遇到的死锁问题
隔离级别为可重复读。
情景一(c2为普通索引)：
begin:
A = update T set c1=1 where c2=2;
if (A is fail){
  insert into T(c1,c2) value(1,2);
}
commit;

若update操作的记录不存在，且此时两个事务t1,t2同时执行上述代码时:
1> t1执行update语句，记录不存在不会加行锁，但会加上间隙锁，间隙锁锁住表T c2 in (1,+∞) 的数据。
2> t2执行update语句，同时加上间隙锁（间隙锁重复加不会冲突），锁住表T c2 in (1,+∞) 的数据。
3> t1执行insert语句，试图插入但被t2持有的T表(1,+∞)间隙锁阻塞
4> t2执行insert语句，试图插入但被t1持有的T表(1,+∞)间隙锁阻塞
解决方案：
避免更新或者删除不存在的记录，虽然更新存在的记录也会产生间隙锁，但是间隙锁锁住的范围会更小；更新不存在的记录会锁住意想不到的区间范围，极易导致死锁问题。

需要注意的是：
非唯一索引更新已存在记录：加行锁和gap锁
唯一索引更新已存在记录：仅加行锁
非唯一索引/唯一索引 更新不存在记录：加gap锁

情景二(c2为普通索引)：
begin:
insert into T(c1,c2) value(0,1);
update T set c1=0 where c2=1;
commit;

当两个事务t1,t2同时执行上述代码时:
1> t1执行insert语句，成功插入一条新的记录record1(1,0,1),并对当前记录加上id=1 这条记录的X锁（排它锁）
2> t2执行insert语句，生成记录record2(2,0,1), 并加上id=2 这条记录的X锁。
3> t1执行update语句，需要对所有符合条件的记录加X锁，已持有record1的X锁，等待获得record2的X锁。
4> t2执行update语句，需要对所有符合条件的记录加X锁，已持有record2的X锁，等待获得record1的X锁。

解决方案：
改成 update T set c1=0 where c2=1 and id=xx;锁的粒度保证尽量小。

310.为什么要分库分表
随着时间和业务的发展，库中的表和表中的数据量都会越来越多，相应地，数据增删改查的开销也会越来越大；一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。

311.分布式事务概念和解决方案？若在通信过程中出现网络原因,如何解决？
一次大的操作由不同的小操作组成，这些小操作分布在不同的服务器和数据库，保证这些小操作的ACID。
解决方案：
1.XA协议两阶段提交：事务管理器+本地资源管理器
  ● 投票：本地事务收到请求执行事务但不提交且阻塞
  ● 事务提交：提交事务通知
  ● 出错后，管理器发起回滚通知
3PC(1.增加超时机制;2.两阶段间插入准备阶段)
2.消息事务+最终一致性：
  ● A系统向消息中间件发送一条预备消息
  ● 消息中间件保存预备消息并返回成功
  ● A执行本地事务
  ● A发送提交消息给消息中间件
3.TCC编程模式(补偿机制、消息重试+接口幂等)：
一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel(服务提供者提供,需幂等)三个操作。

312.分布式寻址方式都有哪些？知道一致性hash吗？手写一下java实现代码？
分片策略：取模、一致性hash、范围约定、自然月分片
一致性hash(将被缓存对象映射到不同的缓存服务器上，都映射到hash环上):
缓存服务器：hash(服务器A的IP地址) % 2^32
被缓存对象：hash(图片名称) % 2^32
从缓存对象的位置出发，沿顺时针方向遇到第一个服务器就是该缓存服务器。
hash环偏斜：添加虚拟节点(实际节点在hash环上的复制品)
java:TreeMap(服务器ip的hash值,服务器ip).taiMap(被缓存对象hash值).firstKey();

313.如何解决分库分表的主键问题？分布式id生成方法
1.数据库自增生成全局唯一递增id，缺点：只能单机
改进：每个写库设置不同的自增长初始值以及相同的增长步长(库数量)，缺点：丧失了绝对递增性
2.单点批量id生成服务，改进：单点+备用服务。缺点：需要远程调用。
3.uuid，缺点：无法保证递增，uuid太长作为主键索引效率低。
4.取当前毫秒数，缺点：并发量不能超过1000。
5.snowflake算法:long型的ID，使用其中41bit作为毫秒数，10bit作为机器编号，12bit作为毫秒内序列号。该算法单机每秒内理论上最多可生成400W的ID。

314.count(*)、count(1)和count(field)区别？
count(*)是对不为null的行进行计数，因此某一行只要不是所有列都为null，就会被计数。count(*)自动会优化指定到某一个字段。
count(field)是对field列不为null的行进行统计，因此某一行的该列为null，则不予计数。
count(1)和count(*)都是统计表的总行数，两者执行结果相同。表上没有主键或者唯一键索引，两者都走全表扫描；表上有主键或者唯一键索引，那么走主键或者唯一键索引。

分布式缓存数据库------------------------------------------------------------------------------------------
401.redis和memcached什么区别？为什么高并发下有时单线程的redis比多线程的memcached效率要高？
区别：
1.mc可缓存图片和视频。rd支持除k/v更多的数据结构;
2.rd可以使用虚拟内存，rd可持久化和aof灾难恢复，rd通过主从支持数据备份;
3.rd可以做消息队列。
原因：mc多线程模型引入了缓存一致性和锁，加锁带来了性能损耗。

402.redis主从复制如何实现的？redis的集群模式如何实现？redis的key是如何寻址的？
主从复制实现：主节点将自己内存中的数据做一份快照，将快照发给从节点，从节点将数据恢复到内存中。之后再每次增加新数据的时候，主节点以类似于mysql的二进制日志方式将语句发送给从节点，从节点拿到主节点发送过来的语句进行重放。
分片方式：
-客户端分片
-基于代理的分片
● Twemproxy
● codis
-路由查询分片
● Redis-cluster（本身提供了自动将数据分散到Redis Cluster不同节点的能力，整个数据集合的某个数据子集存储在哪个节点对于用户来说是透明的）
redis-cluster分片原理：Cluster中有一个16384长度的槽(虚拟槽)，编号分别为0-16383。每个Master节点都会负责一部分的槽，当有某个key被映射到某个Master负责的槽，那么这个Master负责为这个key提供服务，至于哪个Master节点负责哪个槽，可以由用户指定，也可以在初始化的时候自动生成，只有Master才拥有槽的所有权。Master节点维护着一个16384/8字节的位序列，Master节点用bit来标识对于某个槽自己是否拥有。比如对于编号为1的槽，Master只要判断序列的第二位（索引从0开始）是不是为1即可。这种结构很容易添加或者删除节点。比如如果我想新添加个节点D, 我需要从节点A、B、 C中得部分槽到D上。

403.使用redis如何设计分布式锁？说一下实现思路？使用zk可以吗？如何实现？这两种有什么区别？
redis:
1.线程A setnx(上锁的对象,超时时的时间戳t1)，如果返回true，获得锁。
2.线程B 用get获取t1,与当前时间戳比较,判断是是否超时,没超时false,若超时执行第3步;
3.计算新的超时时间t2,使用getset命令返回t3(该值可能其他线程已经修改过),如果t1==t3，获得锁，如果t1!=t3说明锁被其他线程获取了。
4.获取锁后，处理完业务逻辑，再去判断锁是否超时，如果没超时删除锁，如果已超时，不用处理（防止删除其他线程的锁）。
zk:
1.客户端对某个方法加锁时，在zk上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点node1;
2.客户端获取该路径下所有已经创建的子节点，如果发现自己创建的node1的序号是最小的，就认为这个客户端获得了锁。
3.如果发现node1不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待。
4.获取锁后，处理完逻辑，删除自己创建的node1即可。
区别:zk性能差一些，开销大，实现简单。

404.知道redis的持久化吗？底层如何实现的？有什么优点缺点？
RDB:内存到硬盘的快照，定期更新。缺点：耗时，耗性能(fork+io操作)，易丢失数据。
AOF:写日志。缺点：体积大，恢复速度慢。

405.redis过期策略都有哪些？LRU算法知道吗？写一下java代码实现？
过期策略:
定时过期(一key一定时器)，惰性过期：只有使用key时才判断key是否已过期，过期则清除。定期过期：前两者折中。
LRU:new LinkedHashMap<K, V>(capacity, DEFAULT_LOAD_FACTORY, true);
//第三个参数置为true，代表linkedlist按访问顺序排序，可作为LRU缓存；设为false代表按插入顺序排序，可作为FIFO缓存
LRU算法实现：1.通过双向链表来实现，新数据插入到链表头部；2.每当缓存命中（即缓存数据被访问），则将数据移到链表头部；3.当链表满的时候，将链表尾部的数据丢弃。

LinkedHashMap：HashMap和双向链表合二为一即是LinkedHashMap。HashMap是无序的，LinkedHashMap通过维护一个额外的双向链表保证了迭代顺序。该迭代顺序可以是插入顺序（默认），也可以是访问顺序。

406.缓存穿透、缓存击穿、缓存雪崩解决方案？
缓存穿透：指查询一个一定不存在的数据，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，可能导致DB挂掉。
解决方案：1.查询返回的数据为空，仍把这个空结果进行缓存，但过期时间会比较短；2.布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对DB的查询。
缓存击穿：对于设置了过期时间的key，缓存在某个时间点过期的时候，恰好这时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把DB压垮。
解决方案：1.使用互斥锁：当缓存失效时，不立即去load db，先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时再进行load db的操作并回设缓存，否则重试get缓存的方法。2.永远不过期：物理不过期，但逻辑过期（后台异步线程去刷新）。
缓存雪崩：设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。与缓存击穿的区别：雪崩是很多key，击穿是某一个key缓存。
解决方案：将缓存失效时间分散开，比如可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

消息队列------------------------------------------------------------------------------------------
501.为什么使用消息队列？消息队列有什么优点和缺点？
异步处理、应用解耦、流量削峰、日志处理和消息通信

502.kafka、activemq、rabbitmq、rocketmq都有什么优点缺点？
● kafka比ActiveMQ和RabbitMQ更有分布式优势，partition可以冗余存储，若一个partition挂了，可以选主切换到另一台机器继续使用。
● ActiveMQ和RabbitMQ是消费之后就删除消息，没有重复消费的功能。kafka队列中的内容按策略存储一定的时间，消费者自己控制偏移量来读取数据。kafka还维护了每个消费者当前读到的位置。
● 传统的消息队列只有两种模式：要么queue，要么发布订阅。而kafka通过consumer group和队列数据不删除两个概念更加灵活。
● kafka对于有集群要求，尤其是海量数据，以及数据有倾斜问题的场景里（如个别topic的消息非常大，可以通过调整patition数量来解决），比较适合。
● kafka创建topic是一个比较重的操作，因为是分布式需要同步到其他的broker中间要经过zookeeper。而rabbitmq创建几万个topic是很容易的。
● rabbitmq是功能最丰富，最完善的企业级队列。erlang语言难度较大。不支持事务。
● activemq相对来说，显的老套了一些。支持事务。根据用户反馈会出莫名其妙的问题且会丢消息。不适合用于上千个队列的场景。

分布式服务框架------------------------------------------------------------------------------------------
600.dubbo(分布式服务框架)主要解决如下问题：
1.项目服务化后，项目之间的高性能通讯问题。
2.服务的URL管理，当项目拆分为N个服务并且不断增加时，如何有效的管理的服务URL。
3.服务发现和服务移除，动态的管理服务。

601.说一下dubbo的实现过程？注册中心挂了可以继续通信吗？
dubbo服务注册和查找过程：
1.服务提供者在启动时，向注册中心注册自己提供的服务。
2.服务消费者在启动时，向注册中心订阅自己所需的服务。
3.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
4.服务消费者从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
5.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。
官网：
监控中心宕掉不影响使用，只是丢失部分采样数据；数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务。
注册中心对等集群，任意一台宕掉后，将自动切换到另一台；注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯。
服务提供者无状态，任意一台宕掉后，不影响使用；服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复

602.dubbo支持哪些序列化协议？知道hessian的数据结构吗？PB知道吗？为啥他的效率最高？
通信协议：
dubbo:// 协议用的是单一TCP长连接、NIO异步、Hessian序列化、适用于小数据量高并发，消费者远多于提供者。原因：通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用NIO复用线程池。
rmi:// 采用阻塞式短连接和JDK标准序列化方式。适用传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。
hessian:// 采用Http通讯，采用Servlet暴露服务。适用传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。
http:// 基于HTTP表单的远程调用协议，适用传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看。
webservice:// 基于WebService的远程调用协议，适用系统集成，跨语言调用。
thrift:// 对thrif 原生协议的扩展。
序列化协议：
Hessian二进制序列化：实现机制是着重于数据，把对象所有的属性当成一个Map来序列化。Integer a=1→I 1。只传成员属性值和值的类型，不传方法或静态变量。
Java标准二进制序列化：把要序列化的对象类的元数据和业务数据全部序列化为字节流，较可靠。
protobuf：一种数据交换的格式，和JSON，XML一样；pb文件使用一个唯一的id（数字）来代替json里复杂的key，这样只要数据发送方和接收方都用同一套模板文件来解析，可大大提高传输效率。

603.dubbo负载均衡策略和高可用策略都有哪些？动态代理策略都有哪些？
负载均衡策略：按权重进行随机、轮询、最少活跃调用数、一致性hash;
nginx负载均衡：轮询(默认)、指定权重、ip_hash、fair(第三方，按后端服务响应时间)、url_hash(第三方);
动态代理：没有使用CGLib进行代理，而是使用JDK和Javassist来进行动态代理。
注册中心：Multicast（广播）、zookeeper、Redis、Simple（本身就是一个普通的Dubbo服务）
集群容错：读操作建议使用Failover失败自动切换，默认重试两次其他服务器。写操作建议使用Failfast快速失败，发一次调用失败就立即报错。
dubbo配置覆盖优先级：方法级优先，接口级次之，全局配置再次之。如果级别一样，则消费方优先，提供方次之。

604.为什么在Spring中我们能像注入普通本地服务JavaBean一样注入远程的Dubbo服务Bean？
应用：<dubbo:reference id="demoService" interface="com.dubbo.DemoService"/>
@Autowired
private DemoService demoService;
总结：Dubbo的消费者模块中只有接口。
所有的Dubbo消费者Bean都是ReferenceBean类型的对象，interface属性中配置的接口只是让ReferenceBean对象知道Dubbo的服务提供方提供的方法签名而已。使用动态代理动态创建对象。
在Spring容器中，会利用BeanDefinition对象信息来初始化创建之后的Bean对象，但如果你想插手“创建对象”这一步，有两种方法：1.使用工厂方法模式来指定某个工厂方法创建Bean。2. Bean的类实现FactoryBean接口。dubbo采用了第二种。

605.zookeeper原理知道吗？项目中都用到zookeeper哪些功能？其实现算法知道吗？说一下大概原理？
zk是一个分布式的且开源的分布式应用程序协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。提供了文件系统和通信机制功能。
文件系统：znode类型：永久性(断开连接后，节点依然存在)、永久编号性、临时性(断开连接该节点删除)、临时编号性。
通知机制：客户端注册监听它关心的目录节点，当目录节点发生变化（数据改变、被删除、子目录节点增加删除）时，zookeeper会通知客户端。
实现功能：1.命名服务、2.配置管理、3.集群管理、4.分布式锁、5.队列管理
配置管理：逐个修改多台机器上应用程序的配置比较困难，现把这些配置全部放到zk上去，保存在zk的某个目录节点中，然后所有相关应用对这个目录节点进行监听，一旦配置信息发生变化，每个应用就会收到zk的通知，然后从zk获取新的配置信息应用到系统中。
集群管理(是否有机器退出和加入、选举master)：所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与zk的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知。每次选取编号最小的机器作为master就好。

606.netty知道吗？netty可以做什么？NIO、BIO、AIO都是什么？有什么区别？
netty：目的:快速开发高性能、高可靠性的网络服务器和客户端程序；优点:提供异步的、事件驱动的网络应用程序框架和工具。相对tomcat，netty是web server更低层的网络框架。
影响IO操作最关键的两个因素：数据格式或传输方式。
同步阻塞(BIO)：用户进程发起一个IO操作之后，必须等待IO操作完成之后，用户进程才能运行。同步非阻塞(NIO)：用户进程发起一个IO操作以后可以返回做其它事情，但用户进程需要不断的轮询IO操作是否就绪。异步：应用发起IO操作后，不需要等待IO操作完成，等IO操作完成以后会通知应用程序。
BIO：服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理（一客户端一线程）。缺点：当客户端很多时，线程的分配需要一定的内存空间且线程上下文切换也是负担。
NIO：专门线程来分发所有IO事件+事件驱动机制（事件到来时触发，而不是同步的监视事件）+线程间通信方式（wait/notify，保证每次上下文切换都是有意义的）；
Selector模式：单个线程通过selector管理多个channel，从而管理多个网络连接。
三个重要的类selecotr/channel/buffer。有一个单线程Thread线程对应一个Selector，有多个Channel（非阻塞式双向通道，与阻塞式单向的流不同）在Selector上进行注册（每个客户端的socket连接对应一个Channel），每一个Channel下面对应一个Buffer。Thread在这些Channel上不断的进行切换，具体某一时刻切换到哪个Channel，是由事件来决定的。如Channel1想要把数据写入到Buffer1事件发生了，这Selector就会选择Channel1进行处理(一般处理时新开一个线程)，处理的同时Selector还可以切换到其它的Channel上。Buffer本身就是一个内存，底层通过数组实现的，数据的读与写都是通过Buffer来实现的。

区别：NIO不是一个连接就要对应一个处理线程了，而是一个请求对应一个线程，当连接没有数据时，是没有工作线程来处理的。BIO是基于流的，而NIO是基于块的。BIO是一个连接一个线程，NIO是一个请求一个线程，AIO是一个有效请求一个线程。

设计模式------------------------------------------------------------------------------------------
单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点。懒汉式、饿汉式、双重校验锁、静态内部类、枚举类。

代理模式：一个客户不想或者不能够直接引用一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用。
-抽象对象角色：声明了目标对象和代理对象的共同接口；
-目标对象角色：定义了代理对象所代表的目标对象；
-代理对象角色：含有目标对象的引用，提供了与目标对象相同的方法的实现类。
静态代理：由程序员创建代理类，运行前代理类.class已存在；动态代理：在程序运行时通过反射动态生成。
动态代理使用情景：要代理的功能确定了，想批量的给一些类或方法生成代理类。如给某个包下所有以add开头的方法调用前后打印一些日志，或所有DAO结尾的类的所有方法执行前开启事务，执行后提交事务，抛异常时回滚事务。
cglib和jdk动态代理区别:
动态代理让代理类和目标类实现同一个接口(兄弟关系)，使用反射机制，Proxy\InvocationHandler;
cglib生成一个目标类的之类(父子关系)，cglib用ASM直接操作字节码达到运行时动态创建类的效果，Enhancer\MethoInterceptor。
mybatis用的动态代理，spring两者都用(有接口用动态代理，没有接口用cglib)。

适配器模式：将一个类的接口转换成客户希望的另外一个接口。使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。
已固定接口和实现类：日本110v电源接口、日本110V接口实现类、中国220v电源接口、中国220V接口实现类、需要110v的日本电饭煲实现类。
需求：用中国220v电源冒充日本110v电源运行日本电饭煲
适配器实现类‘适配器角色’：implements 日本110v电源接口‘目标角色’，组合中国220v电源接口‘源角色’引用，方法名为110v的方法里调用组合引用的方法名为220v方法。
使用电饭煲：构造中国220v电源实例，并作为参数构造电源适配器实例，适配器实例作为参数构造电饭煲，电饭煲开始工作。
缺省适配器模式：为一个接口提供缺省实现(抽象类)，这样子类型可以从这个缺省实现进行扩展，而不必从原有接口进行扩展增加不需要的方法的空实现。

装饰者模式：动态地给一个对象添加一些额外的功能，继承关系的一个替代方案。
MyReader //专门用于读取数据的公共方法类
  |--MyTextReader // 读取文本数据的类
  |--MyMediaReader // 读取媒体数据的类
需求：将上述两个具体类在不修改原类的情况下分别增加一个缓冲功能。
如果采用继承的方式，那么每个具体类都要生成新的子类而变成体系臃肿。
实现：class MyBufferReader‘装饰角色’ extends MyReader‘抽象构建角色’ {
    private MyReader r;
    MyBufferReader(MyReader r) { }
}
使用：new MyBufferReader‘具体装饰角色’(new MyMediaReader‘具体构件角色’());
代理模式VS装饰模式：两者都现实了各自统一的抽象接口，采用了组合方式，且增加了新功能。但代理模式在代理类中已经指定好了被代理的对象，而装饰模式在包装类需要客户端传入被装饰的是哪一个类。

观察者模式(发布/订阅模式)：定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。
需求：用户登录后，管理登录的方法需要将用户数据(userBean)给各个子系统(订单、券、购物车等)，每当有子系统加入时，需手动修改管理登录方法改为自动。
模式实现：将所有具体观察者抽象出一个接口(‘抽象观察者角色’)，该接口包含了一个得到主题通知更新自己的方法，所有‘具体观察者角色’实现该接口。‘具体主题角色’将所有观察者对象保存在一个List里，并对外提供了一个可以增加和删除观察者对象的方法，当内部状态变化时，给所有已登记的观察者发出通知。

策略模式：定义一系列的算法，把它们一个个封装起来, 并且使它们可相互替换。
需求：卖书系统对不同的会员等级折扣力度不一样，初级0折扣、中级9折、高级8折。
实现：抽象折扣接口‘抽象策略’提供计算图书价格方法，初级、中级和高级分别实现该接口并实现‘具体策略’。价格类‘环境角色’持有一个具体策略对象的引用，且提供根据策略计算价格的包装方法。

工厂模式：将需要的产品和工厂结合在一起，从而得到一个具体需要的产品的一个过程，而无需知道这个产品具体是由谁生产的。
分为简单工厂模式-工厂模式-抽象工厂模式。
需求：Hibernate换数据库只需换方言和驱动就可以。一个调用者想创建一个对象，只要知道其名称就可以了。屏蔽产品的具体实现，调用者只关心产品的接口。
实现：创建一个‘工厂规则’接口，每一个‘工厂商品’继承该接口并实现自己的方法。‘工厂’对外提供一个根据不同的名称/类型参数生产不同的商品对象的方法。
生产商品工厂方法实现方式：1.根据不同的名称/类型参数new并返回不同的商品对象；2.通过具体商品.class反射生成商品对象；3.工厂类中为每个商品的创建对应一个方法。

构建者模式：对象的创建模式(Builder模式)，将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。

工厂模式VS建造者模式：工厂方法模式注重的是整体对象的创建方法，而建造者模式注重的是部件构建的过程，旨在通过一步一步地精确构造创建出一个复杂的对象。

框架原理------------------------------------------------------------------------------------------
701.filter、interceptor和Aspect的区别？
filter只能拿到原始http的请求和响应信息，获得一些参数。拿不到由哪个Controller的哪个方法处理的。因为filter是J2EE规范定义的。因为Controller是SpringMVC定义的东西，想获取真正处理请求方法的信息需要使用interceptor(因它有第三个参数Object handler)，但interceptor无法拿到真正方法参数的值。想拿到真正处理请求方法参数的值需要使用Aspect，但Aspect(只有一个参数ProceedingJoinPoint pjp)是直接拿不到原始http请求和响应的对象。

执行顺序：filter→Interceptor→ControllerAdvice→Aspect→Controller

702.Spring框架中都用到了哪些设计模式？
代理模式—在Aop实现中用到了JDK的动态代理。
单例模式—在spring配置文件中定义的bean默认为单例模式。
模板方法—用来解决代码重复的问题。比如RestTemplate、JmsTemplate、JpaTemplate。
工厂模式—BeanFactory/ApplicationContext用来创建对象的实例。
策略模式-1：加载资源文件的方式，使用了不同的方法，比如：ClassPathResourece、FileSystemResource、ServletContextResource等，但他们都有共同的接口Resource；2：在Aop的实现中，采用了两种不同的方式，JDK动态代理和CGLIB代理。

703.Spring中Bean的生命周期和作用域各是怎样的？
1.首先容器启动后找到Bean定义信息调用构造方法并将其初始化;
2.按照Bean定义配置信息，注入所有的属性;
3.如果Bean实现了各种XXXAware接口，会回调该接口的setXXX()方法;
4.如果Bean含有@PostConstruct注解，则会调用该方法;若bean实现了BeanPostProcessor接口,将调用它的postProcessBeforeInitialization接口方法；
5.如果Bean实现了InitializingBean接口，则会回调该接口的afterPropertiesSet()方法；
6.如果Bean配置了init-method方法，则会执行init-method配置的方法;若bean实现了BeanPostProcessor接口,将调用它的postProcessBeforeInitialization接口方法；
7.经过流程6之后，就可以正式使用该Bean了；容器关闭后，@PreDestroy调用该方法；
8.如果Bean实现了DisposableBean接口，则会回调该接口的destroy()方法；
9.如果Bean配置了destroy-method方法，则会执行destroy-method配置的方法。

Servlet生命周期：init()进行初始化→service()处理客户端的请求→destroy()方法终止→JVM回收Servlet。

Spring对象初始化bean时机：
在默认情况下，只要在Spring容器中配置了一个bean，容器在启动时就会实例化该bean，单例模式。如果在Spring配制文件时设置懒加载模式（lazy-init=”true”），在getBean时才会实例化对象。如果scope=”prototype”时，无论lazy-init的值是什么都只会在使用时才会创建，当struts2的action和spring容器整合的时候，action的scope设置成prototype。

作用域：
singleton：单例模式，Spring IoC容器中只会存在一个共享的Bean实例；
prototype：原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建一个新的Bean实例，每个Bean实例都有自己的属性和状态；
request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会产生新的Bean，而且该bean仅在当前Http Request内有效；
session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请求则会创建新的实例，该bean实例仅在当前Session内有效；
global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在使用portlet context时有效。

705.Spring AOP无法代理方法内部调用的原因？
在使用Spring AOP的时候，我们从IOC容器中获取的Bean对象其实都是代理对象，而不是那些Bean对象本身，由于this关键字引用的并不是该Bean对象的代理对象，而是其本身，因此Spring AOP是不能拦截到这些被嵌套调用的方法的。

706.Spring Bean的加载过程是怎样的？
１、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件的资源；
２、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个<bean>解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中；
３、容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理后器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作：
1）对使用到占位符的<bean>元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象；
2）对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）；
4．Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作；
5．在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作；
6．利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。

707.SpringMVC执行流程和工作原理
1、用户发送请求至前端控制器DispatcherServlet。
2、DispatcherServlet收到请求调用HandlerMapping处理器映射器(根据请求的url查找Handler)。
3、HandlerMapping找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器生成HandlerExecutionChain一并返回给DispatcherServlet。
4、DispatcherServlet调用HandlerAdapter处理器适配器。
5、HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。
HandlerMapping和HandlerAdapter区别：前者是用来找到url对应的处理handler对象，而不是找到url对应的处理函数。后者则是用来匹配到handler的某个具体的处理函数上，准备参数并调度执行这个函数。
6、Controller执行完成返回ModelAndView。HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。
7、DispatcherServlet将ModelAndView传给ViewReslover视图解析器，ViewReslover解析后返回具体View。
8、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）并响应给用户。

708.Mybatis工作原理
Mybatis作用：消除了几乎所有的JDBC代码和参数的手动设置以及结果集的检索，普通javaBean映射成数据库中的记录。
MyBatis应用程序通过Resources加载XML配置文件初始化Configuration，创建SqlSessionFactory，SqlSessionFactory再根据配置(配置来源于两个地方：一处是配置文件、一处是Java代码的注解)获取一个SqlSession。SqlSession包含了执行sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后关闭SqlSession。

Mybatis缓存：一级缓存是SqlSession缓存，默认开启的，如未提交的事务第二次查询相同的SQL会直接从缓存中取。二级缓存是指mapper映射文件，作用域是同一个namespace下的mapper映射文件内容，多个SqlSession共享，默认不开启。

709.RateLimter原理（令牌桶算法）?其它限流方式？
假设希望每秒最多发送5个请求，相当于每0.2秒发送一个。
- 当第一个请求发送后，记为开始，即0秒。
- 0.1秒时，来了第二个请求，这时候还没到第0.2秒（可以认为当前令牌数为0），那么我们不需要考虑别的，等到0.2秒就能执行，但是必须知道，这时候，下次允许执行的请求时间应该是第0.4秒了。
- 假如第二个请求执行完后，到2.0秒还是没有新的请求到来，那么我们可以理解0.4秒到2秒的空闲时间就保存了5个令牌（最多不能超过5个，而且这个计算实际上是在新请求到来的时刻计算出来的）。
- 当2.1秒时，有新请求进来了
如果它需要消耗3个请求，那么它可以立刻执行，然后存储令牌就变成了2个，而且如果此时再有新请求进来，可以立刻执行（smoothbursty，平滑突发限流），或者等待一个消耗3个存储令牌的积分时间执行（smoothwarmingup，平滑预热限流）。
如果它需要消耗9个请求，那么它可以立刻执行，然后存储令牌清空，而且如果此时再有新请求进来，需要等待4个令牌的时间0.8秒（smoothbursty），或者等待一个消耗5个存储令牌的积分时间执行加上等待4个令牌的时间（smoothwarmingup）。
结论：
RateLimiter不需要记住上个请求的时间，它只需要记住“希望下个请求到来的时间”。这样使得我们能够马上识别出，一个确切的超时时间（跟tryAcquire(timeout)相关）是否满足下一个计划时间点。 如果当前时间大于“期望的下个请求到来的时间”，那么这两个时间的差值就是Ratelimiter的未使用时间t，通过t*QPS计算出storedPermits。
自实现：
counter=CacheBuilder.newBuilder().expireAfterWrite(1, TimeUnit.SECONDS).build(new CacheLoader<>(){AtomicLong load(Long seconds){return new AtomicLong(0);}});
if(counter.get(当前时间).incrementAndGet()>5) {//被限流了}

710.Guava Cache的数据结构和底层实现

711.springboot自动配置的原理
在spring程序main方法中添加@SpringBootApplication或者@EnableAutoConfiguration，会自动去maven中读取每个starter中的spring.factories文件，该文件里配置了所有需要被创建spring容器中的bean。

712.Spring容器-ApplicationContext的启动过程
https://www.cnblogs.com/andypeker/p/7016967.html

其它------------------------------------------------------------------------------------------
801.linux相关
lsof –i (4、6、协议、:端口、@ip) 列出符合条件的进程
dig:域名查询工具 [dig baidu.com]
!$代表上一个命令最后的字符串
批量替换字符串：
sed -i "s/查找字段/替换字段/g" `grep 查找字段 -rl 路径`

802.网络七层协议
应用层(HTTP、TELNET、FTP)、表示层、会话层、传输层(TCP、UDP)、网络层(IP、ICMP)、数据链路层、物理层。
前三层合并为一层应用层的为网络五层模型。

TCP三次握手：
1:建立连接时，客户端发送SYN(i)到服务器，并进入SYN_SEND状态，等待服务器确认；(SYN:synchronous)
2:服务器收到SYN，发送一个ACK(i+1)确认，同时自己也发送一个SYN(j)，即SYN+ACK包，此时服务器进入SYN_RECV状态；(ACK:Acknowledgement)
3:客户端收到服务器的SYN＋ACK包，向服务器发送确认ACK(j+1)，此包发送完毕，客户端和服务器进入ESTABLISHED(已建立的)状态，完成三次握手。

TCP四次挥手：
1.断开连接时，客户端发送一个FIN(m)，用来关闭客户端到服务端的数据传送，客户端进入FIN_WAIT_1状态；(FIN:finish)
2.服务端收到FIN后，发送ACK(m+1)确认，表示同意客户端关闭请求了，并进入CLOSE_WAIT状态；客户端收到后进入FIN_WAIT_2状态；
3.服务端发送一个FIN(n)，用来关闭服务端到客户端的数据传送，服务端进入LAST_ACK状态；
4.客户端收到FIN后，发送一个ACK(n+1)确认，并进入TIME_WAIT状态，服务端收到后进入CLOSED状态，完成四次挥手。

为什么数据库连接很耗资源？资源消耗主要集中在网络上，建立TCP连接需要三次握手，然后客户端发送认证包(用于用户验证)，再进行一些连接变量的设置(比如字符集、是否自动提交事务等)。

803.微信红包怎么实现的（如群里有人发了一个N人的红包，总金额为M）？
一、发红包后台操作：
在db（sharding）中增加一条红包记录(含字段：红包总金额、红包总个数、剩余红包个数、剩余红包金额；同时扣减发红包人的钱)，并设置过期时间；
在分布式Cache中增加一条记录，存储抢红包的人数N和总额M。
二、抢红包后台操作：
抢红包分为抢和拆，抢操作在Cache层完成，通过原子减操作（带版本号的CAS，冲突的用户放行进行拆操作）进行红包数递减，到0就说明抢光了，最终实际进入后台拆操作的量不大，通过操作的分离将无效请求直接挡在Cache层外面。
拆红包在db完成，通过db事务操作（cas更新红包记录【剩余红包个数、剩余红包金额】、插入领取流水记录），入账为异步操作。拆的时候会实时计算金额（非预分配），其金额为1分到剩余平均值2倍之间随机数，最大的红包为M*2/N（且不会超过M），当拆了红包后会更新剩余金额和个数。
秒杀系统：https://mp.weixin.qq.com/s/5aMN9SqaWa57rYGgtdAF_A

804.java8和java9新特性
java8：
Lambda 表达式−Lambda允许把函数作为一个方法的参数。
方法引用−方法引用可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，
默认方法−默认方法就是一个在接口里面有了一个实现的方法。
Stream API−新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。
Date Time API−加强对日期与时间的处理。
Optional 类−用来解决空指针异常。
java9：
模块化-采用模块化系统的应用程序只需要这些应用程序所需的那部分JDK模块，而非是整个JDK框架了。
集合工厂方法增强-如集合的不可修改视图的创建。
钻石操作符允许在匿名类上使用。
支持HTTP2和WebSocket协议的API。
HTML5风格的Java帮助文档。

805.单点登录设计
实现逻辑：通过cookie验证用户的身份，配置拦截器拦截所有请求，当访问站点时，拦截方法中判断客户端是否存在指定cookie以及是否有效，满足条件则跳主页面，否则跳登录页面。当登录并验证成功后定义cookie并写入客户端。只要不同应用都使用同一cookie规约，他们就是相互信任。
同域SSO：系统检测(包括有效期)并解析cookie的key和value（如pub系统会解析获取登录openId），若有效则跳到主页面；否则跳转到登录页，登录页接口检查用户名和密码正确后，将key和value写入cookie。
同父域SSO：如1.x.com和2.x.com，需新增统一校验接口check.x.com；系统1.x.com获取cookie的key和value，并作为参数服务调用check.x.com接口，check.x.com判断cookie是否有效(包括有效期)，1.x.com收到返回若判断有效，则跳到主页面；若无效或者根本获取不到cookie，跳转到check.x.com的登录接口，check.x.com登录接口检查用户名和密码正确后，写入.x.com父域cookie。
完全跨域SSO：如a.com和b.com，需新增统一校验接口x.com；系统a.com获取cookie的key和value，并作为参数服务调用x.com接口，x.com检查cookie的key和value是否有效，若有效则跳到主页面；若无效或根本拿不到cookie则跳转到a.com的登录页，a.com的登录页接口拿到用户名和密码以后，作为参数服务调用x.com的登录接口，x.com判断用户名和密码是否有效。若a.com收到返回若判断有效后，a.com和b.com对应的添加cookie的接口列表给前端，用户在前端页面主动或被动发起a.com和b.com的添加cookie的接口调用，该接口负责将cookie的key和value设置在a.com或b.com自己域名下。

806.互联网架构为什么要做服务化？
痛点一：代码到处拷贝。如各个业务线都通过自己DAO写SQL访问user库来获取用户数据。
痛点二：复杂性扩散。如从db获取用户数据架构中加入了缓存，各个业务线需要关注缓存的引入被迫升级（对于写操作，先淘汰cache再写数据）。
痛点三：SQL质量得不到保障，业务相互影响。如业务线A写了一个全表扫描的SQL，导致数据库的CPU100%，影响了所有的业务线。
痛点四：疯狂的DB耦合。通过join数据库user表来实现各自业务线自己的业务逻辑，将导致所有业务线db耦合在一起无法垂直拆分。
服务化好处：调用方爽、提高了代码复用性、屏蔽底层复杂度(不需要关注缓存或分库分别的细节)、数据库解耦。缺点：分布式事务无法保证强一致性。

SOA与微服务区别：1-微服务比SOA更加精细，微服务更多的以独立的进程的方式存在，互相之间并无影响；2-微服务提供的接口更加通用化，例如HTTP RESTful方式，各种终端都可以调用，无关语言、平台限制；3-微服务更倾向于分布式去中心化的部署方式，在互联网业务场景下更适合。

服务治理：服务发现注册、服务监控、集群容错、负载均衡；服务化拆分原则：面向业务、单一职责、分而治之。

807.海量数据处理
● Hash法：哈希表。用于快速存取、统计某些数据，将大量数据进行分类。例如提取某日访问网站次数最多的IP地址等。
● Bit-map：使用位数组来表示某些元素是否存在。用于海量数据的快速查找、判重、删除等。如从8位电话号码中查找重复号码或统计不同号码的个数（可用多个bit表示一个数）。
● Bloom Filter：位数组+k个hash函数。定义m位初始化都为0的数组，每个函数都可以将元素映射到某一位。判断某个元素是否属于集合时，查看k个位是否全部为1。缺点：若都为1存在错误率、无法删除元素。如检查英文单词是否拼写正确、邮箱过滤垃圾邮件、找出两个各存放50亿条URL的文件中共同的URL。
● 数据库优化法：创建索引、配置缓存、切表分表、数据采样。
● 倒排索引法：正向索引用来存储每个文档的单词的列表，反向索引则是单词指向了包含它的文档。如常见的学术论文的关键词搜索。
● 外排序法：内存不能一次处理待排序的对象，必须把它以文件的形式存放于外存，排序时(归并排序)再把他们一部分一部分地调入内存进行处理。用于大文件的排序以及去重。
● Trie树：前缀树。根节点不包含字符，除根节点外的每一个子节点都包含一个字符。从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。每个节点包含构成单词数量count。用于词频统计、前缀匹配、字符串排序。
● 堆：二叉堆。适用于海量数据求前N大（小顶堆）、前N小（大顶堆）或中位数（双堆）问题。如100w个数中找最大的前100个数。
● 双层桶：分而治之。因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。如5亿个整数中找出不重复的整数的个数（内存装不下）。将数据分离到不同的区域文件，不同的区域在利用bitmap来解决。
● MapReduce法：将数据划分并交给不同的机器去处理，结果归约。

808.从输入网址到浏览器呈现页面内容，中间发生了什么？
https://mp.weixin.qq.com/s/q9wDvplWysHCn_Bet8j5lA
http code:301-永久性转移、302-暂时性转移、304-Not Modified（Last-Modified和ETag）、405-method not allowed。

http错误码415是怎么引起的？
415：Unsupported Media Type，请求中提交的实体并不是服务器中所支持的格式，请求被拒绝。
-未在HTTP报文的请求头中正确的指定Content-Type；
-User-Agent未伪装成浏览器被服务器拒绝了请求。

http的method是OPTIONS和TRACE方法做什么用？
OPTIONS：可以询问服务器通常支持哪些方法，或者对某些特殊资源支持哪些方法。
TRACE：回显服务器收到的请求，主要用于测试或诊断。

809.HTTP、HTTPS、SSL、TLS的理解？
TLS实际上是SSL 3.0以上版本。
HTTPS交互过程：https://www.wosign.com/info/https_tls_ssl_http.htm

810.分布式索引怎么做？怎么保障数据一致性、实时性如何保障？

811.nginx里面limit_req和limit_conn的区别？

812.常用算法和数据结构(情景题)
linkedList（单\双向）、二叉树、动态规划
http://www.hawstein.com/posts/dp-novice-to-advanced.html

https://mp.weixin.qq.com/s/wme9AutrG3vqNjk4aIPbeA
https://blog.csdn.net/fangqun663775/article/details/73614850
https://mp.weixin.qq.com/s/VgSgRwM32YyICe4TFKSVrQ
http://www.spring4all.com/article/716


java基础hashmap并发map get resize过程 泛型。
各种锁 aqs cas，synchronize，volatile 底层原理。
classloader jmm gc 对象分配 安全点框架spring dubbo cloud rpc原理 
编码通信netty 服务注册与发现zk原理，限流算法，缓存策略，
服务降级数据库索引结构与优化 死锁 事务实现。redis数据类型 
存储结构 失效策略。mq使用场景。分布式理论cap base 分布式事务处理 
分布式锁实现。soa 微服务区别。



